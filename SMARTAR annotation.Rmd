---
title: "Annotated review with code for SMART-AR"
author: Woochan H.
output: html_document
---

### Introduction
Motivation for using dynamic treatment regime analysis in depression care is explained as follows:

> As the management of depression may involve multiple treatment components given over a period of time, a successful intervention is likely a direct result of administering each component or their combination in an optimal sequence, possibly based on intermediate outcomes, with an objective to maximize the eventual health outcome. Thus, the optimal intervention is potentially a dynamic treatment regimen. ...In an attempt to improve care of patients with depression after acute coronary syndrome, Davidson et al. (2013) compare a centralized depression care approach to standard care in the Comparison of Depression Interventions after Acute Coronary Syndrome (CODIACS) Vanguard trial. The trial adopted the stepped care approach, whereby initial treatments were chosen based on patient preference or standard care, and then “stepped” based on intermediate symptoms in the treatment arm. As a result, patients in CODIACS received different treatment sequences.

The CODAICS-QoL trial that they have utilized to test SMART-AR was NOT designed in principle for the purpose of testing dynamic treatment regimes. The data used in this study is focused on the first intervention arm of the CODIACS-QoL trial which delivers "stepped care" as part of the intervention package. The details of the trial are summarised in the next section.

The motivation for the use of adaptive randomisation in the context of SMART is proposed as:

> A regular SMART design randomizes subjects to available treatment options according to pre-specified probabilities, ... a typical strategy aims to achieve equal sample sizes across possible treatment sequences (Murphy, 2005b). This approach in theory maximizes the comparative power for comparing two treatment sequences, but it is at odds with the objective of an implementation study. In addition, in order to cover all possible branches of treatment sequences, a SMART design may suffer from the “curse of dimensionality”. In drug trials ... it is quite common to use the play-the-winner strategy, whereby a patient with a positive intermediate outcome will stay on the same treatment. ... playing the winner is not necessarily the ethical or optimal approach for behavioral interventions.

### CODIAS-QoL Trial
**Objective:** To determine whether systematically screening for depression in survivors of ACS improves quality of life and depression compared with usual care.

**Participants:** Multisite randomized trial, 1500 patients with ACS in the previous 2 to 12 months and had no prior history of depression. Intention-to-treat analysis.

**Interventions:** Randomly assigned (1:1:1) to receive:

(1) [screen, notify, treat] screening with PHQ-8 questionnaire, with notification of primary care clinicians and provision of ***stepped depression care***;

(2) [screen, notify] screening, with notification of primary care clinicians for those with positive screening results;

(3) [no screen] usual care

**Stepped care includes,** a) participant preference for either brief, cognitive behavioral therapy (CBT, in this context equivalent to problem solving therapy or PST), delivered centrally by telephone, or antidepressant medication managed at the local site, or both, or neither, and b) review of progress at approximately 2-month intervals, with "stepping up" of care if sufficient progress is not being realized.

**Outcomes:** The primary outcome was change in quality-adjusted life-years. Secondary outcome was depression-free days.

**Results:** Only 71 of 1000 eligible survivors of ACS (treatment group 1&2, 7.1%) had elevated scores indicating depressive symptoms at screening. No differences in mean (SD) change in quality-adjusted life-years or cumulative mean (SD) depression-free days. Harms including death, bleeding, or sleep difficulties did not differ among groups.

### Methods
```{r, results='hide'}
source('SMARTAR sim.R') # load simulation provided by authors
library(knitr)
library(png)
```

#### Q-learning
Notations:

* $A_{ti}$ : treatment given to patient i at stage t
* $S_{t}$ : set of treatment options at stage t, where $A_{ti} \in S_{t}$
* $J_{t}$ :  number of treatment options at stage t
* $H_{ti}$ : history for patient i at stage t
* $Y_i$ : health outcome for patient i
* $\pi_t(a \mid h_{ti})$ : probability of ith patient being enrolled to stage t intervention a, typically $1/J_{t}$ in non-adaptive DTR
* $d_{t}^{*}(h_{t}) \in S_{t}$ : optimal decision given patient history

We focus on a 2 stage DTR setting where the Q-functions are defined as:

* $Q_2(h_2,a_2) = E [Y_i \mid H_{2i} = h_2, A_{2i} = a_2]$
* $Q_1(h_1,a_1) = E [max_{a2 \in s2} Q_2(H_{2i}, a_2) \mid H_{1i} = h_1, A_{1i} = a_1]$

Because the optimal DTR, $d_{t}^{*}(h_{t}) \in S_{t}$, is intractable, we estimate the Q-function using linear regression

* $Q_t(h_t,a_t; \theta_t) = \theta_{t0} + \theta_{t1}^T(h_t) + \theta_{t2}^T(a_t) + \theta_{t3}^T(h_ta_t)$

* $\hat{\theta}_2 = arg min_\theta \sum_{i=1}^{n} (Y_i - Q_2(H_{2i}, A_{2i}; \theta))^2$

For Q1 we define a pseudo-outcome $\hat{Y}_i$ as a proxy for the expectation defined and estimate the parameters using least squares for the pseudo-outcome.

* $\hat{Y}_i = max_{a2 \in s2} Q2(H_{2i}, a_2; \hat{\theta}_2)$

* $\hat{\theta}_1 = arg min_\theta \sum_{i=1}^{n} (\hat{Y}_i - Q_1(H_{1i}, A_{1i}; \theta))^2$


```{r}
# pseudo-outcome, return largest Q2 given possible action space
Q2max = function(a1,resp,b0,b1,b2,b3,g1,g2,g3) {  # resp = binary variable, intermediate outcome to a1
  Q20 = Q2(a1,resp,0,b0,b1,b2,b3,g1,g2,g3)
  Q21 = Q2(a1,resp,1,b0,b1,b2,b3,g1,g2,g3)
  if (Q20 >= Q21)  return( c(0,Q20) )
  else { return( c(1,Q21) ) }
}
# p = probability of responding to treatment a1 (i.e. P[resp = 1 | Ai = a1])
# not used in fitting Q-function
Q1 = function(a1,b0,b1,b2,b3,g1,g2,g3,p) {
  val = (1-p)*Q2max(a1,0, b0,b1,b2,b3,g1,g2,g3)[2] + p*Q2max(a1,1,b0,b1,b2,b3,g1,g2,g3)[2]
  return(val)
}
```


#### SMART with adaptive randomisation
Let $n(i)$ denote the number of patients with the final outcome evaluated just prior to enrollment of patient i (likely n(i) < i-1 as patients enroll in a staggered fashion). Let $N_{min}$ be a pre-specified number of patients, where the allocation probability is a pre-specified and static value, $\pi_t^0(a \mid h_{ti})$, for all patients where $n(i) < N_{min}$.

The authors define the adaptive randomisation policy $\hat{\pi}_t(a \mid h_{ti})$ for $n(i) \geq N_{min}$ as:

* $\hat{\pi}_t(a \mid h_{ti}) = \frac{\hat{\rho}(a \mid h_{ti})}{\sum_{a \in s_t}\hat{\rho}(a \mid h_{ti})}$
* where $\hat{\rho}(a \mid h_{ti}) = \exp(\frac{Q_t(h_t,a_t; \hat{\theta}_t)}{\hat{\sigma}_t}log(b))$ and $\hat{\sigma}_t^2 = \frac{\sum_{k=1}^{n(i)}{(\hat{Y}_k} - Q_t(h_{tk},a_{tk}; \hat{\theta}_t))^2}{n(i) - dim(\theta_t)}$
* $dim(\theta)$ denotes the dimension of the vector $\theta$ and pre-specified base b ≥ 1 represents how "greedy" the AR scheme is.

The authors also integrate historical context by using a weighted average of $\pi_t^0$ and $\hat{\pi}_t$ using hyperparameter $\lambda \in [0,1]$ which decreases as $n(i)$ grows. Thus, the historical $\pi_t^0$ influences the randomization probabilities even after AR is in effect, although its contribution goes to zero as $n(i)$ increases when b > 1.

* $\tilde{\rho}_t = exp((\lambda^{b-1})\pi_t^0 + (1- \lambda^{b-1})\hat{\pi}_t)$
* $\lambda_n = \tau^{1/(b-1)}N_{min}/n$

```{r}
# Patient outcomes and arrival times
eps = rnorm(n,0,sigma)  # sample size n <- 100
arrival = c(0, cumsum(rexp(n-1,rate=accrate)))  # accrate (number of patients/month) = 4
# Intermediate response rate for A1
p0 = 29/56
p1 = 28/52
```

> The intermediate responses (R) were generated as Bernoulli with Pr(R = 1|A1 = 0) = 0.52 and Pr(R = 1|A1 = 1) = 0.54 based on the results in CODIACS. In each simulated trial, inter-enrollment times were simulated according to a Poisson process with a rate of four patients per month based on our clinical expectation.

```{r}
# iterated over n patients
for (i in 1:n) {
  indcomp = which(arrival < (arrival[i] - 6))  # True when patient outcome is available (arrival + 6 months trial duration)
  ncomp = length(indcomp)

  # AR does not begin until there are n1 (= Nmin) complete observations
  if (ncomp < n1)  {
    # STAGE 1 of DTR
    a1[i] = rbinom(1,1,pi1)  # pi1(initial random allocation prob determined from CODIACS) = 0.67
    if (a1[i]==0)  R[i] = rbinom(1,1,p0)  # p0 (prob of improvement with PST at baseline from CODIACS) = 29/56
    else R[i] = rbinom(1,1,p1)  # p1 (prob of improvement without PST from CODIACS) = 28/52

    # STAGE 2 of DTR
    if (a1[i]==0 & R[i]==0) a2[i] = rbinom(1,1,pi2[1])
    else if (a1[i]==0 & R[i]==1) a2[i] = rbinom(1,1,pi2[2])
    else if (a1[i]==1 & R[i]==0) a2[i] = rbinom(1,1,pi2[3])
    else a2[i] = rbinom(1,1,pi2[4])
  }
  # AR begins n(i) > Nmin
  else {
    y = Q2sat(a1,R,a2) + eps
    ycomp = y[indcomp]
    a1comp = a1[indcomp]
    a2comp = a2[indcomp]
    Rcomp = R[indcomp]

    # regression model to calculate pi
    foo = cbind(a1comp,Rcomp,a2comp,ycomp)
    pfoo = getRandProb(foo,base=base)
    pi1hat = pi11hat = pfoo$PI1[2]
    pi10hat = pfoo$PI1[1]

    # weighted average for historical context integration
    w0 = (tau/ncomp)^{base-1}  # define lambda
    w1 = 1-w0
    rho10 = exp(w0*log(pi10) + w1*log(pi10hat))
    rho11 = exp(w0*log(pi11) + w1*log(pi11hat))
    pi1til = rho11  / (rho10 + rho11)  # stage 1
    pi20hat = pfoo$PI2[,3]
    pi2hat = pi21hat = pfoo$PI2[,4]
    rho20 = exp(w0*log(pi20) + w1*log(pi20hat))
    rho21 = exp(w0*log(pi21) + w1*log(pi21hat))
    pi2til = rho21 / (rho20+rho21)  # stage 2

    # STAGE 1 of DTR
    a1[i] = rbinom(1,1,pi1til)
    if (a1[i]==1)  R[i] = rbinom(1,1,p1)
    else R[i] = rbinom(1,1,p0)

    # STAGE 2 of DTR
    if (a1[i]==0 & R[i]==0) a2[i] = rbinom(1,1,pi2til[1])
    else if (a1[i]==0 & R[i]==1) a2[i] = rbinom(1,1,pi2til[2])
    else if (a1[i]==1 & R[i]==0) a2[i] = rbinom(1,1,pi2til[3])
    else a2[i] = rbinom(1,1,pi2til[4])
  }
}
```

#### Design Parameters
The hyperparameters used for tuning the defined SMART-AR approach are:

* $b$ : indicates how "greedy" the AR scheme is. Non-adaptive SMART when $b = 1$, and larger $b > 1$ are more aggressive.
* $N_{min}$ : indicating how early the AR scheme begins. Set to be $> 3 \times max_t(dim(\theta_t))$ based on experience.
* $\lambda$ : defined as $\lambda_n = \tau^{1/(b-1)}N_{min}/n$ where a larger $\tau$ leads to more attenuation.

### Application: Depression Treatment Programme

#### Analysis of historical data: specification of $\pi_t^0$
The authors set up the initial randomization probabilities $\pi_0^t$ in the SMART-AR using the data of CODIACS, in which information about $(Ati, Ri, Yi)$ is available in 108 subjects with 56 receiving no PST and 52 receiving PST at baseline. Let $R_i$ denote successful treatment outcome (i.e. decreased severity on depression questionnaire) at intermediate evaluation. *Only 71 patients tested positive from the screening in intervention group 1 (screen, notify, treat). Therefore the data must include those that were allocated to group 2 (screen, notify) but received treatment based on the primary clinician's discretion.*

* $Q_2(h_{2i},a_{2i}; \theta_2) = \beta_0 + \beta_1a_{1i} + \beta_2a_{2i} + \beta_3a_{1i}a_{2i} + \gamma_1r_i + \gamma_2r_i(1-a_{1i})a_{2i} + \gamma_3r_ia_{1i}(1-a_{2i})$

The Q-function $Q_2(h_{2i},a_{2i}; \theta_2)$ is parameterized so that a negative value of $\gamma_2$ and $\gamma_3$ will support play-the-winner respectively for medication and PST as initial treatment. The $(1-a_i)$ forces $a_1 = a_2$ to maximize the Q-value when $\gamma < 0$. This is used for comparing various design strategies in the next section. $Q_1$ is fitted with a simple linear modelling with the pseudo-outcome defined by $Q_2(max)$.

* $Q_1(h_{1i}, a_{1i}; \theta_1) = \alpha_0 + \alpha_1a_{1i}$

```{r}
# Apply Q-learning to the data for STAGE 2
Q2 = function(a1,resp,a2,b0,b1,b2,b3,g1,g2,g3) {  # resp = binary variable, intermediate outcome to a1
  b0 + b1*a1 + b2*a2 + b3*a1*a2 + g1*resp + g2*resp*(1-a1)*a2 + g3*resp*a1*(1-a2)
}
```

#### Summary of Q-learning of the CODIACS data

The probabilities $\hat{\pi}^{CODIACS}_t$ are calculated with b = 2, and are used as historical randomization probabilities π0t in the SMART-AR for the depression treatment program. Mean squared errors due to $\hat{\theta}_t$ are $\hat{\sigma}^2_1 = 24.6$ and $\hat{\sigma}^2_2 = 45.2$.

```{r echo=FALSE, out.width = "50%", fig.align="center"}
img1_path <- "figures/Q-learning_summary.png"
img1 <- readPNG(img1_path, native = TRUE)
include_graphics(img1_path)
```

In other words, the optimal sequence is non-dynamic in that it starts with PST and switches to medication regardless of the intermediate response. It is instructive to also look at the results for patients starting with medication $(a1i = 0)$: the optimal follow-up decision in stage 2 will be switching to PST for patients who do not respond $(ri = 0)$ and staying on medication for those who do $(ri = 1)$. This analysis supports playing the winner for medication as the initial treatment.

The authors also perform analysis with a saturated Q-function defined as below to test the robustness of the analysis. Note the ordering of coefficients for $\gamma_2r_ia_{2i}$ and $\gamma_3r_ia_{1i}$, and that it reduces to $Q_2$ defined above when $\gamma_4 = -(\gamma_2 + \gamma_3)$.

* $Q_2^{Sat}(h_{2i},a_{2i}; \theta_2) = \beta_0 + \beta_1a_{1i} + \beta_2a_{2i} + \beta_3a_{1i}a_{2i} + \gamma_1r_i + \gamma_2r_ia_{2i} + \gamma_3r_ia_{1i} + \gamma_4r_ia_{1i}a_{2i}$

Applying Q-learning with $Q_2^{Sat}$ resulted in the same optimal sequence (dˆ1 = 1, dˆ2 = 0) as that with $Q_2^{Sat}$; this was equivalent to choosing the strategy with maximum marginal means. Also, the Q-functions are estimated with very similar values with $\hat{Q}_1(0) = 10.7$ and $\hat{Q}_1(1) = 15.4$. It indicates that the parameterization of $Q_2$ is adequate, while slightly more parsimonious than $Q_2^{Sat}$.

```{r}
# Q-learning for STAGE 2 under saturated conditions
Q2sat = function(a1,resp,a2, theta0) {
  dim(theta0) = c(8,1)
  x = cbind(1, a1, a2, resp, a1*a2, a1*resp, a2*resp, a1*a2*resp)
  return( x %*% theta0)
}

# All possible DTRs and their values, V0 defined in sim.R
print(V0,digits=3)
```


#### Design callibration
Experimentation to find optimal design parameters discussed above. The optimal parameters were found to be $b = 10$, $N_{min} = 30$, and $\tau = 0.75$. Parameter values for $Q^{sat}_2(h_{2i},a_{2i})$ used in simulation, and the corresponding optimal d* and worst dw. Scenarios 1–4, under which $Q_2(h_{2i},a_{2i}; \theta_2)$ is correct, are used as calibration scenarios for the SMART-AR design. The analysis model (4) is misspecified under Scenarios 5 and 6.

### Design Comparison
Simulations were performed to compare the following scenarios:

* SMART-AR(opt): optimal allocation strategy with $b = 10$, $N_{min} = 30$, and $\tau = 0.75$
* SMART-AR(1): non-adaptive strategy based on CODIACS initial probability with $b = 1, \hat{\pi} = \pi^0$
* SMART-B: non-adaptive strategy with equal allocation $\pi_t = 1/J_t$
* SMART-PTW: non-adaptive  strategy with play-the-winner, where patients responding to A1 will continue on A2 = A1
* sMART-PTW(m): play-the-winner for medication only, and $\pi_t = 1/J_t$ otherwise.

### Discussion


### Reference
Cheung, Ying Kuen, Bibhas Chakraborty, and Karina W. Davidson. "Sequential multiple assignment randomized trial (SMART) with adaptive randomization for quality improvement in depression treatment program." Biometrics 71.2 (2015): 450-459.

Kronish, Ian M., et al. "Effect of depression screening after acute coronary syndromes on quality of life: the CODIACS-QoL randomized clinical trial." JAMA Internal Medicine 180.1 (2020): 45-53.
